{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e924ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all imports out of the way\n",
    "import tensorneat as tn\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3adb6b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3768, 1050)\n"
     ]
    }
   ],
   "source": [
    "# drop nans split by symbol and join on date\n",
    "file_path = \"hist_data/stocks/sp500_stocks.csv\"  # Update this path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "symbols = df['Symbol'].unique()\n",
    "symbol_dfs = {symbol: df[df['Symbol'] == symbol] for symbol in symbols}\n",
    "\n",
    "merged_df = symbol_dfs[symbols[0]].set_index('Date')\n",
    "\n",
    "for symbol in symbols[1:]:\n",
    "    symbol_data = symbol_dfs[symbol].set_index('Date')\n",
    "    if (len(symbol_data) == 3768):\n",
    "        merged_df = merged_df.join(symbol_data, how='inner', rsuffix=f\"_{symbol}\")\n",
    "\n",
    "tensorneat_input = merged_df.to_numpy()\n",
    "\n",
    "print(tensorneat_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d22733cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Symbol  Adj Close     Close      High       Low      Open  \\\n",
      "Date                                                                   \n",
      "2010-01-04    AOS   5.937266  7.435000  7.480000  7.261667  7.295000   \n",
      "2010-01-05    AOS   5.861404  7.340000  7.431667  7.308333  7.431667   \n",
      "2010-01-06    AOS   5.864068  7.343333  7.405000  7.301667  7.335000   \n",
      "2010-01-07    AOS   5.881369  7.365000  7.425000  7.311667  7.356667   \n",
      "2010-01-08    AOS   5.967879  7.473333  7.485000  7.311667  7.331667   \n",
      "\n",
      "               Volume Symbol_ABT  Adj Close_ABT  Close_ABT  ...    Low_WMB  \\\n",
      "Date                                                        ...              \n",
      "2010-01-04  1104600.0        ABT      18.763718  26.129908  ...  17.445280   \n",
      "2010-01-05  1207200.0        ABT      18.612118  25.918797  ...  17.534952   \n",
      "2010-01-06   663000.0        ABT      18.715481  26.062737  ...  17.771360   \n",
      "2010-01-07   564000.0        ABT      18.870522  26.278646  ...  18.072985   \n",
      "2010-01-08   504600.0        ABT      18.966991  26.412991  ...  18.113745   \n",
      "\n",
      "             Open_WMB  Volume_WMB  Symbol_WTW Adj Close_WTW  Close_WTW  \\\n",
      "Date                                                                     \n",
      "2010-01-04  17.477888   7020240.0         WTW     52.549011  70.913910   \n",
      "2010-01-05  17.534952   7415481.0         WTW     52.431255  70.754967   \n",
      "2010-01-06  17.909945  12157139.0         WTW     53.275311  71.894043   \n",
      "2010-01-07  18.390911   6181305.0         WTW     53.118282  71.682121   \n",
      "2010-01-08  18.268633   4703754.0         WTW     53.059380  71.602646   \n",
      "\n",
      "             High_WTW    Low_WTW   Open_WTW  Volume_WTW  \n",
      "Date                                                     \n",
      "2010-01-04  70.913910  69.854301  70.781456    348017.0  \n",
      "2010-01-05  71.576157  70.198677  70.596024    339523.0  \n",
      "2010-01-06  72.000000  70.278145  70.860924    585049.0  \n",
      "2010-01-07  72.582779  71.311256  72.132446    328689.0  \n",
      "2010-01-08  71.788078  71.311256  71.470200    279388.0  \n",
      "\n",
      "[5 rows x 1050 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e77ab1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3767, 150)\n",
      "(3767,)\n"
     ]
    }
   ],
   "source": [
    "# create a target array\n",
    "\n",
    "close_columns = [col for col in merged_df.columns if col.split('_')[0] == 'Close']\n",
    "\n",
    "# features and target prep\n",
    "'''\n",
    "feature_df = merged_df[close_columns].copy()\n",
    "for c in close_columns:\n",
    "    feature_df[f'{c}_ma5'] = feature_df[c].rolling(window=5).mean()\n",
    "    feature_df[f'{c}_ma10'] = feature_df[c].rolling(window=10).mean()\n",
    "    feature_df[f'{c}_ma20'] = feature_df[c].rolling(window=20).mean()\n",
    "    feature_df[f'{c}_avg_change_13'] = feature_df[c].pct_change().rolling(window=13).mean()\n",
    "    feature_df[f'{c}_stddev_13'] = feature_df[c].pct_change().rolling(window=13).std()\n",
    "print(feature_df.values.shape)\n",
    "'''\n",
    "\n",
    "# shift target and adjust features accordingly\n",
    "target = merged_df[close_columns].pct_change().shift(-1).values[:-1,:]\n",
    "features = merged_df[close_columns].pct_change().values[1:,:]\n",
    "print(target.shape)\n",
    "\n",
    "print(jnp.argmax(target, axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cea5d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count: 3767\n",
      "Train Size: 3013\n",
      "Shape of INPUTS: (3013, 150)\n",
      "Shape of RETURNS: (3013, 150)\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "train_test_split = 0.8\n",
    "\n",
    "sample_count = target.shape[0]\n",
    "print(f\"Sample Count: {sample_count}\")\n",
    "train_size = int(sample_count * train_test_split)\n",
    "print(f\"Train Size: {train_size}\")\n",
    "TEST_INPUTS = features[train_size:, :]\n",
    "TEST_RETURNS = target[train_size:, :]\n",
    "INPUTS = features[:train_size, :]\n",
    "RETURNS = target[:train_size, :]\n",
    "\n",
    "print(f\"Shape of INPUTS: {INPUTS.shape}\")\n",
    "print(f\"Shape of RETURNS: {RETURNS.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af6106c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jax.numpy as jnp\n",
    "from tensorneat.problem.base import BaseProblem\n",
    "import tensorneat.algorithm.neat as neat_algorithm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "EPISODE_LEN = 34\n",
    "\n",
    "class TradingProblem(BaseProblem):\n",
    "  jitable = True\n",
    "  episode_len = EPISODE_LEN\n",
    "  pop_size = 100\n",
    "  \n",
    "  def __init__(self):\n",
    "      super().__init__()\n",
    "      self.pop_counter = 0\n",
    "      self.start_idx = random.randint(0, INPUTS.shape[0] - self.episode_len)\n",
    "      self.end_idx = self.start_idx + self.episode_len\n",
    "\n",
    "  @property\n",
    "  def input_shape(self):\n",
    "    return (INPUTS.shape[1],)\n",
    "\n",
    "  @property\n",
    "  def output_shape(self):\n",
    "    return (1,)\n",
    "\n",
    "  def evaluate(self, state, randkey, act_func, params):\n",
    "      # Get the network's outputs for all inputs\n",
    "      actions = jax.vmap(act_func, in_axes=(None, None, 0))(state, params, INPUTS)\n",
    "      \n",
    "      # Find the index of the maximum output for each day\n",
    "      selected_indices = jnp.argmax(actions, axis=1)\n",
    "      \n",
    "      # Calculate the reward based on the selected index\n",
    "      reward = jnp.take_along_axis(RETURNS, selected_indices[:, None], axis=1).squeeze()\n",
    "      \n",
    "      # Return the mean reward\n",
    "      return jnp.mean(reward)\n",
    "\n",
    "  def show(self, state, randkey, act_func, params, *args, **kwargs):\n",
    "      # Get actions as a host numpy array\n",
    "      actions = jax.vmap(act_func, in_axes=(None, None, 0))(state, params, TEST_INPUTS)\n",
    "      selected_indices = jnp.argmax(actions, axis=1)\n",
    "\n",
    "      # Move data to host numpy\n",
    "      from jax import device_get\n",
    "      import numpy as np\n",
    "      selected_indices_np = np.asarray(device_get(selected_indices)).ravel()\n",
    "      returns_np = np.asarray(device_get(TEST_RETURNS))\n",
    "\n",
    "      # Ensure indices are within bounds\n",
    "      num_columns = returns_np.shape[1]\n",
    "      selected_indices_np = np.clip(selected_indices_np, 0, num_columns - 1)\n",
    "\n",
    "      # Calculate performance based on selected indices\n",
    "      perf = 100.0\n",
    "      perf_hist = []\n",
    "      for i in range(len(selected_indices_np)):\n",
    "          selected_return = returns_np[i, selected_indices_np[i]]\n",
    "          perf += perf * float(selected_return)\n",
    "          perf_hist.append(float(perf))\n",
    "\n",
    "      # Plot using numpy list of floats\n",
    "      import matplotlib.pyplot as plt\n",
    "      plt.plot(perf_hist)\n",
    "      print(\"Initial performance:\", perf_hist[0])\n",
    "      print(\"Final performance:\", perf_hist[-1])\n",
    "      plt.show()\n",
    "\n",
    "# Assuming INPUTS and RETURNS are defined from previous cells\n",
    "trading_problem = TradingProblem()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9f8da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jax.numpy as jnp\n",
    "from tensorneat.problem.base import BaseProblem\n",
    "import tensorneat.algorithm.neat as neat_algorithm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "EPISODE_LEN = 34\n",
    "\n",
    "class TradingProblemTopK(BaseProblem):\n",
    "  jitable = True\n",
    "  episode_len = EPISODE_LEN\n",
    "  pop_size = 100\n",
    "  \n",
    "  def __init__(self):\n",
    "      super().__init__()\n",
    "      self.pop_counter = 0\n",
    "      self.start_idx = random.randint(0, INPUTS.shape[0] - self.episode_len)\n",
    "      self.end_idx = self.start_idx + self.episode_len\n",
    "\n",
    "  @property\n",
    "  def input_shape(self):\n",
    "    return (INPUTS.shape[1],)\n",
    "\n",
    "  @property\n",
    "  def output_shape(self):\n",
    "    return (1,)\n",
    "\n",
    "  def evaluate(self, state, randkey, act_func, params, k=5):\n",
    "      # Get the network's outputs for all inputs\n",
    "      actions = jax.vmap(act_func, in_axes=(None, None, 0))(state, params, INPUTS)\n",
    "      \n",
    "      # Get the top-k values and indices\n",
    "      topk_values, topk_indices = jax.lax.top_k(actions, k)\n",
    "      \n",
    "      # Apply softmax to the top-k values to get weights\n",
    "      softmax_weights = jax.nn.softmax(topk_values, axis=1)\n",
    "      \n",
    "      # Gather the rewards for the top-k indices\n",
    "      rewards = jnp.take_along_axis(RETURNS, topk_indices, axis=1)\n",
    "      \n",
    "      # Calculate the weighted reward\n",
    "      weighted_rewards = jnp.sum(softmax_weights * rewards, axis=1)\n",
    "      \n",
    "      # Return the mean reward\n",
    "      return jnp.mean(weighted_rewards)\n",
    "\n",
    "  def show(self, state, randkey, act_func, params, k=5, *args, **kwargs):\n",
    "      # Get actions as a host numpy array\n",
    "      actions = jax.vmap(act_func, in_axes=(None, None, 0))(state, params, TEST_INPUTS)\n",
    "      \n",
    "      # Get the top-k values and indices\n",
    "      topk_values, topk_indices = jax.lax.top_k(actions, k)\n",
    "      \n",
    "      # Apply softmax to the top-k values to get weights\n",
    "      softmax_weights = jax.nn.softmax(topk_values, axis=1)\n",
    "      \n",
    "      # Move data to host numpy\n",
    "      from jax import device_get\n",
    "      import numpy as np\n",
    "      topk_indices_np = np.asarray(device_get(topk_indices))\n",
    "      softmax_weights_np = np.asarray(device_get(softmax_weights))\n",
    "      returns_np = np.asarray(device_get(TEST_RETURNS))\n",
    "      \n",
    "      # Calculate performance based on top-k weighted rewards\n",
    "      perf = 100.0\n",
    "      perf_hist = []\n",
    "      for i in range(len(topk_indices_np)):\n",
    "          # Gather the rewards for the top-k indices\n",
    "          rewards = returns_np[i, topk_indices_np[i]]\n",
    "          \n",
    "          # Calculate the weighted reward\n",
    "          weighted_reward = np.sum(softmax_weights_np[i] * rewards)\n",
    "          \n",
    "          # Update performance\n",
    "          perf += perf * float(weighted_reward)\n",
    "          perf_hist.append(float(perf))\n",
    "      \n",
    "      # Plot using numpy list of floats\n",
    "      import matplotlib.pyplot as plt\n",
    "      plt.plot(perf_hist)\n",
    "      print(\"Initial performance:\", perf_hist[0])\n",
    "      print(\"Final performance:\", perf_hist[-1])\n",
    "      plt.show()\n",
    "\n",
    "# Assuming INPUTS and RETURNS are defined from previous cells\n",
    "trading_problem = TradingProblemTopK()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d990dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to ./model_archive/tensorneat_checkpoints\n",
      "initializing\n",
      "initializing finished\n",
      "start compile\n",
      "compile finished, cost time: 3.598619s\n",
      "Generation: 1, Cost time: 42425.30ms\n",
      " \tfitness: valid cnt: 89, max: 0.0025, min: -0.0017, mean: 0.0007, std: 0.0006\n",
      "\n",
      "\tnode counts: max: 304, min: 302, mean: 303.04\n",
      " \tconn counts: max: 901, min: 600, mean: 879.85\n",
      " \tspecies: 1, [89]\n",
      "\n",
      "Generation: 2, Cost time: 43049.32ms\n",
      " \tfitness: valid cnt: 89, max: 0.0032, min: -0.0005, mean: 0.0010, std: 0.0006\n",
      "\n",
      "\tnode counts: max: 304, min: 301, mean: 302.65\n",
      " \tconn counts: max: 902, min: 300, mean: 768.65\n",
      " \tspecies: 1, [89]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorneat.pipeline import Pipeline\n",
    "from tensorneat.algorithm.neat import NEAT\n",
    "from tensorneat.genome import DefaultGenome, BiasNode, DefaultConn, DefaultMutation\n",
    "from tensorneat.problem.func_fit import CustomFuncFit\n",
    "from tensorneat.common import ACT, AGG\n",
    "from tensorneat import algorithm\n",
    "\n",
    "# Construct the pipeline and run\n",
    "pipeline = Pipeline(\n",
    "    algorithm=NEAT(\n",
    "        pop_size=89,\n",
    "        species_size=8,\n",
    "        survival_threshold=0.1,\n",
    "        compatibility_threshold=0.8,\n",
    "        genome=DefaultGenome(\n",
    "            max_nodes=500,\n",
    "            max_conns=1500,\n",
    "            num_inputs=features.shape[1],\n",
    "            num_outputs=target.shape[1],\n",
    "            init_hidden_layers=(3,),\n",
    "            node_gene=BiasNode(\n",
    "                bias_init_std=0.1,\n",
    "                bias_mutate_power=0.05,\n",
    "                bias_mutate_rate=0.01,\n",
    "                bias_replace_rate=0.0,\n",
    "                activation_options=ACT.tanh,\n",
    "                aggregation_options=AGG.sum,\n",
    "            ),\n",
    "            conn_gene=DefaultConn(\n",
    "                weight_init_mean=0.0,\n",
    "                weight_init_std=0.1,\n",
    "                weight_mutate_power=0.05,\n",
    "                weight_replace_rate=0.0,\n",
    "                weight_mutate_rate=0.001,\n",
    "            ),\n",
    "            output_transform=ACT.tanh,\n",
    "        ),\n",
    "    ),\n",
    "    problem=TradingProblem(),\n",
    "    generation_limit=100,\n",
    "    fitness_target=.01,\n",
    "    seed=42,\n",
    "    is_save=True,\n",
    "    save_dir=\"./model_archive/tensorneat_checkpoints\"\n",
    ")\n",
    "\n",
    "# initialize state\n",
    "state = pipeline.setup()\n",
    "# run until terminate\n",
    "state, best = pipeline.auto_run(state)\n",
    "# show result\n",
    "pipeline.show(state, best)\n",
    "state.save(\"./model_archive/tensorneat_checkpoints/evolving_state.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40d6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
