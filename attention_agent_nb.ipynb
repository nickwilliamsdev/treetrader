{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693727e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nick5\\miniconda3\\envs\\tree-env\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from networks.attention_agent import CausalAttentionAgent\n",
    "import torch\n",
    "from utils.trading_gym_env import TradingEnv\n",
    "from utils.synthetic_data_service import SyntheticOHLCVGenerator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from diffevo import DDIMScheduler, BayesianGenerator\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from utils.fitess_funcs import batched_fitness_function\n",
    "from api_wrappers.kraken_wrapper import KrakenWrapper\n",
    "kw = KrakenWrapper()\n",
    "dfs = kw.load_hist_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31284976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "         date      open      high       low     close      vwap           vol\n",
      "0  1694390400  0.249169  0.249169  0.236997  0.242000  0.241745  1.630805e+06\n",
      "1  1694476800  0.242000  0.252356  0.240993  0.245998  0.248591  1.011622e+06\n",
      "2  1694563200  0.245534  0.249705  0.243873  0.248728  0.247799  2.463036e+05\n",
      "3  1694649600  0.248832  0.252286  0.246532  0.251329  0.249129  1.596386e+05\n",
      "4  1694736000  0.251267  0.254644  0.237800  0.250528  0.244553  3.753199e+06\n",
      "         date     open     high      low    close     vwap            vol\n",
      "0  1694390400  0.09131  0.09202  0.08760  0.08844  0.08886   44115.023285\n",
      "1  1694476800  0.08896  0.09198  0.08859  0.08965  0.09029  191172.611332\n",
      "2  1694563200  0.08921  0.09195  0.08900  0.09089  0.09070   78639.702407\n",
      "3  1694649600  0.09122  0.09379  0.09050  0.09347  0.09216  121614.765609\n",
      "4  1694736000  0.09352  0.09671  0.09328  0.09630  0.09462   86333.150052\n",
      "         date    open    high     low   close    vwap          vol\n",
      "0  1694390400  1.2198  1.2198  1.1311  1.1487  1.1673  6822.234274\n",
      "1  1694476800  1.1652  1.1703  1.1379  1.1386  1.1538   872.268600\n",
      "2  1694563200  1.1300  1.1582  1.1102  1.1299  1.1309  4223.990165\n",
      "3  1694649600  1.1638  1.1860  1.1139  1.1139  1.1564  4504.505068\n",
      "4  1694736000  1.1000  1.1210  1.0793  1.1116  1.1056  5313.608973\n",
      "         date    open    high     low   close    vwap          vol\n",
      "0  1694390400  6.6333  6.6333  6.3000  6.3599  6.4940  5451.541525\n",
      "1  1694476800  6.3613  6.5581  6.3613  6.3873  6.4660  1694.123271\n",
      "2  1694563200  6.3947  6.5701  6.3947  6.5417  6.4847  3135.148908\n",
      "3  1694649600  6.5529  6.8976  6.5079  6.8379  6.6994  2149.232908\n",
      "4  1694736000  6.8103  7.0331  6.7749  6.9191  6.8904  4165.244683\n",
      "         date  open  high   low  close  vwap          vol\n",
      "0  1694390400  9.41  9.50  9.06   9.19  9.23  2256.650783\n",
      "1  1694476800  9.25  9.57  9.21   9.21  9.39  1049.288491\n",
      "2  1694563200  9.19  9.44  9.12   9.31  9.25  1391.003770\n",
      "3  1694649600  9.30  9.46  9.28   9.40  9.35   608.969089\n",
      "4  1694736000  9.41  9.51  9.22   9.44  9.32  4781.857899\n",
      "         date    open    high     low   close    vwap         vol\n",
      "0  1694390400  190.36  191.14  181.71  183.48  186.53   51.574878\n",
      "1  1694476800  184.55  209.07  184.55  198.85  203.28  414.533961\n",
      "2  1694563200  198.56  204.09  196.35  201.07  200.50  142.405865\n",
      "3  1694649600  199.96  209.46  199.26  208.12  204.94   67.970166\n",
      "4  1694736000  207.30  224.96  206.26  217.55  218.17  357.038927\n",
      "         date     open     high      low    close     vwap            vol\n",
      "0  1694390400  1.00040  1.00056  1.00022  1.00025  1.00034   61497.915893\n",
      "1  1694476800  1.00028  1.00117  0.99995  0.99998  1.00028  172658.046050\n",
      "2  1694563200  1.00012  1.00025  0.99976  0.99989  1.00006   89670.538152\n",
      "3  1694649600  0.99992  1.00018  0.99969  0.99993  0.99995  133444.717953\n",
      "4  1694736000  0.99981  1.00026  0.99971  1.00003  1.00012  692269.641825\n",
      "         date    open    high     low   close    vwap            vol\n",
      "0  1694390400  4.1415  4.1523  3.9142  3.9834  4.0051  254694.983290\n",
      "1  1694476800  3.9857  4.0890  3.9575  3.9887  4.0079   39629.523454\n",
      "2  1694563200  3.9816  4.1013  3.9545  3.9992  4.0163   72752.145127\n",
      "3  1694649600  4.0029  4.0840  3.9738  4.0595  4.0264   42150.233147\n",
      "4  1694736000  4.0607  4.1701  4.0534  4.1442  4.1084   15600.836809\n",
      "         date    open    high     low   close    vwap            vol\n",
      "0  1689379200  0.7683  0.8013  0.7568  0.7707  0.7710   89463.879782\n",
      "1  1689465600  0.7722  0.7949  0.7439  0.7567  0.7651   81150.173793\n",
      "2  1689552000  0.7511  0.7903  0.7333  0.7779  0.7649  127509.854350\n",
      "3  1689638400  0.7773  0.7773  0.7393  0.7548  0.7542   59784.736478\n",
      "4  1689724800  0.7611  0.7771  0.7493  0.7600  0.7627   49414.861205\n",
      "         date     open     high      low    close     vwap          vol\n",
      "0  1694390400  1617.68  1617.90  1532.48  1552.08  1565.00  2582.913194\n",
      "1  1694476800  1552.09  1622.27  1549.69  1592.74  1595.52  1627.532214\n",
      "2  1694563200  1590.73  1618.19  1583.29  1606.75  1604.23   663.804445\n",
      "3  1694649600  1606.82  1643.62  1606.82  1626.73  1625.95  1163.510575\n",
      "4  1694736000  1626.35  1652.13  1612.36  1641.39  1623.32   596.880044\n",
      "         date     open     high      low    close     vwap           vol\n",
      "0  1694390400  6.01900  6.01900  5.74771  5.82564  5.82452  35464.963488\n",
      "1  1694476800  5.82340  6.05561  5.82340  5.97272  5.95454  20728.028294\n",
      "2  1694563200  5.97398  6.08000  5.93192  6.01720  6.00954  10166.212870\n",
      "3  1694649600  6.03019  6.20379  6.01032  6.15036  6.11541   4570.637298\n",
      "4  1694736000  6.16196  6.36929  6.12170  6.36279  6.19619  22419.512222\n",
      "         date      open      high       low     close      vwap          vol\n",
      "0  1694390400  61.14959  61.61980  57.79815  58.83104  60.11379  3770.742027\n",
      "1  1694476800  58.77154  61.37298  58.68315  59.88467  60.34201  2858.163314\n",
      "2  1694563200  59.98366  62.80000  59.69886  61.95304  61.24263  3581.336888\n",
      "3  1694649600  62.00051  63.33778  61.98346  62.79187  62.68853  3690.950945\n",
      "4  1694736000  62.85436  66.17833  62.64528  65.88331  63.57458  4018.778506\n",
      "         date     open     high      low    close     vwap            vol\n",
      "0  1694390400  0.28185  0.28242  0.26534  0.26900  0.27341  139962.609754\n",
      "1  1694476800  0.26953  0.28102  0.26845  0.27119  0.27444   60186.225147\n",
      "2  1694563200  0.26855  0.28037  0.26595  0.28037  0.27169   42487.414511\n",
      "3  1694649600  0.28169  0.29525  0.27969  0.28939  0.28955   16953.439303\n",
      "4  1694736000  0.29031  0.29690  0.28998  0.29690  0.29375    4330.564943\n",
      "         date      open      high       low     close      vwap           vol\n",
      "0  1694390400  0.000007  0.000007  0.000007  0.000007  0.000007  1.786039e+09\n",
      "1  1694476800  0.000007  0.000007  0.000007  0.000007  0.000007  8.376201e+08\n",
      "2  1694563200  0.000007  0.000007  0.000007  0.000007  0.000007  1.311891e+09\n",
      "3  1694649600  0.000007  0.000007  0.000007  0.000007  0.000007  4.552901e+08\n",
      "4  1694736000  0.000007  0.000007  0.000007  0.000007  0.000007  3.174376e+09\n",
      "         date   open   high    low  close   vwap           vol\n",
      "0  1694390400  18.23  18.42  17.37  17.69  17.61  36069.854491\n",
      "1  1694476800  17.71  18.78  17.59  17.90  18.30  24582.045187\n",
      "2  1694563200  17.95  18.54  17.70  18.38  18.12  19244.237531\n",
      "3  1694649600  18.40  19.29  18.40  18.84  18.93   7080.129031\n",
      "4  1694736000  18.80  19.47  18.59  19.15  18.99   2754.559869\n",
      "         date    open    high     low   close    vwap           vol\n",
      "0  1694390400  1.0003  1.0006  0.9999  1.0003  1.0003  4.315316e+06\n",
      "1  1694476800  1.0003  1.0005  1.0000  1.0001  1.0002  1.483941e+07\n",
      "2  1694563200  1.0001  1.0003  0.9998  0.9999  1.0000  6.051834e+06\n",
      "3  1694649600  1.0000  1.0003  0.9997  0.9999  0.9999  6.957548e+06\n",
      "4  1694736000  0.9999  1.0002  0.9998  1.0001  1.0000  7.030479e+06\n",
      "         date     open     high      low    close     vwap           vol\n",
      "0  1694390400  0.01221  0.01238  0.01170  0.01188  0.01188  1.409647e+06\n",
      "1  1694476800  0.01192  0.01217  0.01178  0.01217  0.01187  4.597031e+05\n",
      "2  1694563200  0.01191  0.01209  0.01175  0.01204  0.01181  1.511837e+05\n",
      "3  1694649600  0.01211  0.01243  0.01203  0.01226  0.01228  8.392202e+05\n",
      "4  1694736000  0.01222  0.01275  0.01206  0.01261  0.01241  6.759663e+05\n",
      "         date     open     high      low    close     vwap         vol\n",
      "0  1694390400  25846.0  25896.6  24917.4  25167.7  25369.6  638.706526\n",
      "1  1694476800  25163.8  26520.0  25136.1  25829.6  25987.0  669.534677\n",
      "2  1694563200  25840.1  26400.0  25771.6  26216.8  26108.5  285.325887\n",
      "3  1694649600  26226.8  26848.3  26131.2  26533.5  26518.4  397.757723\n",
      "4  1694736000  26527.4  26876.7  26232.7  26601.3  26505.4  221.816795\n",
      "         date     open     high      low    close     vwap           vol\n",
      "0  1694390400  0.06116  0.06194  0.05930  0.06026  0.06067  4.649975e+05\n",
      "1  1694476800  0.06069  0.06236  0.06069  0.06085  0.06125  2.194773e+06\n",
      "2  1694563200  0.06097  0.06159  0.06055  0.06124  0.06112  6.621813e+05\n",
      "3  1694649600  0.06136  0.06247  0.06113  0.06203  0.06181  1.478846e+06\n",
      "4  1694736000  0.06212  0.06292  0.06145  0.06249  0.06201  9.230924e+05\n",
      "         date    open    high     low   close    vwap          vol\n",
      "0  1694390400  143.39  143.57  138.18  139.34  142.30   272.972657\n",
      "1  1694476800  140.09  142.85  139.59  140.90  141.28   438.801037\n",
      "2  1694563200  140.78  144.54  140.78  143.28  142.74   481.024380\n",
      "3  1694649600  143.28  147.00  141.19  146.16  143.45  1040.748624\n",
      "4  1694736000  146.66  149.13  146.36  147.18  147.70   735.068481\n",
      "         date     open     high      low    close     vwap           vol\n",
      "0  1694390400  0.49715  0.49715  0.45968  0.47444  0.47534  1.671362e+06\n",
      "1  1694476800  0.47213  0.48673  0.47040  0.48043  0.47908  5.309443e+05\n",
      "2  1694563200  0.48045  0.48915  0.47200  0.48396  0.47916  5.252967e+05\n",
      "3  1694649600  0.48327  0.49345  0.48020  0.48889  0.48837  4.069757e+05\n",
      "4  1694736000  0.49004  0.50800  0.48782  0.50010  0.49590  6.137035e+05\n",
      "         date    open    high     low   close    vwap          vol\n",
      "0  1694390400  0.6701  0.6701  0.6409  0.6460  0.6515  4705.232707\n",
      "1  1694476800  0.6433  0.6578  0.6344  0.6362  0.6397  2901.349066\n",
      "2  1694563200  0.6373  0.6508  0.6305  0.6476  0.6407  5429.204283\n",
      "3  1694649600  0.6449  0.6535  0.6385  0.6521  0.6484  2351.475884\n",
      "4  1694736000  0.6562  0.6765  0.6551  0.6758  0.6624  1681.542999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick5\\AppData\\Local\\Temp\\ipykernel_23640\\6427933.py:56: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  states = torch.tensor(states, dtype=torch.float32)  # Shape: (num_samples, seq_len, num_features)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print(len(dfs))\n",
    "\n",
    "def add_features(df):\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    print(df.head())\n",
    "    # Ensure columns are numeric\n",
    "    df['close'] = pd.to_numeric(df['close'], errors='coerce')\n",
    "    df['high'] = pd.to_numeric(df['high'], errors='coerce')\n",
    "    df['low'] = pd.to_numeric(df['low'], errors='coerce')\n",
    "    df['vol'] = pd.to_numeric(df['vol'], errors='coerce')\n",
    "\n",
    "    # Add log returns\n",
    "    df['log_return'] = np.log(df['close']).diff()\n",
    "\n",
    "    # Add moving averages\n",
    "    df['ma_10'] = df['close'].rolling(window=10).mean()\n",
    "    df['ma_50'] = df['close'].rolling(window=50).mean()\n",
    "\n",
    "    # Add Fibonacci levels\n",
    "    fib_ratios = [0.0, 0.236, 0.382, 0.5, 0.618, 1.0]\n",
    "    for ratio in fib_ratios:\n",
    "        df[f'fib_{int(ratio * 1000)}'] = np.nan\n",
    "    for i in range(20, len(df)):\n",
    "        high = df['high'].iloc[i-20:i].max()\n",
    "        low = df['low'].iloc[i-20:i].min()\n",
    "        for ratio in fib_ratios:\n",
    "            level = high - (high - low) * ratio\n",
    "            df.at[i, f'fib_{int(ratio * 1000)}'] = level\n",
    "\n",
    "    # Drop NaN rows\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    return df\n",
    "train_size = int(len(list(dfs.items())[0][1]) * 0.6)\n",
    "# Add features to all dataframes\n",
    "dfs = {asset: add_features(df) for asset, df in dfs.items()}\n",
    "def split_train_test(df, train_ratio=0.8):\n",
    "    train_df = df.iloc[:train_size]\n",
    "    test_df = df.iloc[train_size:]\n",
    "    return train_df, test_df\n",
    "\n",
    "# Split all dataframes into train/test sets\n",
    "train_test_data = {asset: split_train_test(df) for asset, df in dfs.items()}\n",
    "def prepare_data(df, seq_len):\n",
    "    states = []\n",
    "    price_changes = []\n",
    "\n",
    "    for i in range(len(df) - seq_len):\n",
    "        state = df.iloc[i:i+seq_len][['log_return', 'ma_10', 'ma_50']].values\n",
    "        price_change = df.iloc[i+seq_len]['log_return']\n",
    "        states.append(state)\n",
    "        price_changes.append(price_change)\n",
    "\n",
    "    states = torch.tensor(states, dtype=torch.float32)  # Shape: (num_samples, seq_len, num_features)\n",
    "    price_changes = torch.tensor(price_changes, dtype=torch.float32)  # Shape: (num_samples,)\n",
    "    return states, price_changes\n",
    "\n",
    "# Prepare data for all assets\n",
    "seq_len = 144\n",
    "train_data = {asset: prepare_data(train, seq_len) for asset, (train, _) in train_test_data.items()}\n",
    "test_data = {asset: prepare_data(test, seq_len) for asset, (_, test) in train_test_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9e2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Selected assets for this generation: ['EOSUSDT.txt', 'XTZUSDT.txt', 'XBTUSDT.txt', 'USDCUSDT.txt', 'BCHUSDT.txt', 'DOTUSDT.txt', 'USTUSDT.txt', 'LTCUSDT.txt', 'APEUSDT.txt', 'LINKUSDT.txt']\n",
      "Step 232, Best Reward: 0.26497510075569153\n",
      "Selected assets for this generation: ['BCHUSDT.txt', 'SHIBUSDT.txt', 'XBTUSDT.txt', 'DAIUSDT.txt', 'EOSUSDT.txt', 'APEUSDT.txt', 'LINKUSDT.txt', 'XDGUSDT.txt', 'XMRUSDT.txt', 'USTUSDT.txt']\n",
      "Step 231, Best Reward: 0.26956456899642944\n",
      "Selected assets for this generation: ['SHIBUSDT.txt', 'ETHUSDT.txt', 'APEUSDT.txt', 'ALGOUSDT.txt', 'DAIUSDT.txt', 'LTCUSDT.txt', 'USDCUSDT.txt', 'ADAUSDT.txt', 'XMRUSDT.txt', 'MANAUSDT.txt']\n",
      "Step 230, Best Reward: 0.2962484657764435\n",
      "Selected assets for this generation: ['MANAUSDT.txt', 'AVAXUSDT.txt', 'SOLUSDT.txt', 'EOSUSDT.txt', 'ALGOUSDT.txt', 'XRPUSDT.txt', 'XTZUSDT.txt', 'DOTUSDT.txt', 'USDCUSDT.txt', 'BCHUSDT.txt']\n",
      "Step 229, Best Reward: 0.30556756258010864\n",
      "Selected assets for this generation: ['ALGOUSDT.txt', 'SHIBUSDT.txt', 'USTUSDT.txt', 'SOLUSDT.txt', 'APEUSDT.txt', 'AVAXUSDT.txt', 'XTZUSDT.txt', 'EOSUSDT.txt', 'XRPUSDT.txt', 'LTCUSDT.txt']\n",
      "Step 228, Best Reward: 0.26849251985549927\n",
      "Selected assets for this generation: ['ATOMUSDT.txt', 'EOSUSDT.txt', 'XRPUSDT.txt', 'SHIBUSDT.txt', 'LINKUSDT.txt', 'DAIUSDT.txt', 'ALGOUSDT.txt', 'ETHUSDT.txt', 'XBTUSDT.txt', 'APEUSDT.txt']\n",
      "Step 227, Best Reward: 0.2703332304954529\n",
      "Selected assets for this generation: ['XTZUSDT.txt', 'USTUSDT.txt', 'DAIUSDT.txt', 'MANAUSDT.txt', 'LTCUSDT.txt', 'XBTUSDT.txt', 'ATOMUSDT.txt', 'SOLUSDT.txt', 'XDGUSDT.txt', 'ALGOUSDT.txt']\n",
      "Step 226, Best Reward: 0.27505040168762207\n",
      "Selected assets for this generation: ['XTZUSDT.txt', 'XMRUSDT.txt', 'LINKUSDT.txt', 'EOSUSDT.txt', 'DOTUSDT.txt', 'APEUSDT.txt', 'XRPUSDT.txt', 'USTUSDT.txt', 'BCHUSDT.txt', 'XBTUSDT.txt']\n",
      "Step 225, Best Reward: 0.26095348596572876\n",
      "Selected assets for this generation: ['LTCUSDT.txt', 'XBTUSDT.txt', 'ADAUSDT.txt', 'DAIUSDT.txt', 'AVAXUSDT.txt', 'XMRUSDT.txt', 'BCHUSDT.txt', 'XRPUSDT.txt', 'SHIBUSDT.txt', 'USTUSDT.txt']\n",
      "Step 224, Best Reward: 0.3160659074783325\n",
      "Selected assets for this generation: ['LTCUSDT.txt', 'AVAXUSDT.txt', 'SHIBUSDT.txt', 'ALGOUSDT.txt', 'DOTUSDT.txt', 'XBTUSDT.txt', 'APEUSDT.txt', 'MANAUSDT.txt', 'XTZUSDT.txt', 'XRPUSDT.txt']\n",
      "Step 223, Best Reward: 0.2739516496658325\n",
      "Selected assets for this generation: ['USDCUSDT.txt', 'XDGUSDT.txt', 'XMRUSDT.txt', 'DAIUSDT.txt', 'USTUSDT.txt', 'EOSUSDT.txt', 'LINKUSDT.txt', 'XBTUSDT.txt', 'XRPUSDT.txt', 'APEUSDT.txt']\n",
      "Step 222, Best Reward: 0.2969074547290802\n",
      "Selected assets for this generation: ['ETHUSDT.txt', 'SHIBUSDT.txt', 'XMRUSDT.txt', 'DOTUSDT.txt', 'EOSUSDT.txt', 'MANAUSDT.txt', 'DAIUSDT.txt', 'BCHUSDT.txt', 'XRPUSDT.txt', 'ALGOUSDT.txt']\n",
      "Step 221, Best Reward: 0.28405314683914185\n",
      "Selected assets for this generation: ['XRPUSDT.txt', 'XBTUSDT.txt', 'ALGOUSDT.txt', 'APEUSDT.txt', 'USDCUSDT.txt', 'DAIUSDT.txt', 'XTZUSDT.txt', 'BCHUSDT.txt', 'DOTUSDT.txt', 'MANAUSDT.txt']\n",
      "Step 220, Best Reward: 0.2927306294441223\n",
      "Selected assets for this generation: ['LINKUSDT.txt', 'XDGUSDT.txt', 'BCHUSDT.txt', 'AVAXUSDT.txt', 'XTZUSDT.txt', 'XBTUSDT.txt', 'ADAUSDT.txt', 'USTUSDT.txt', 'ALGOUSDT.txt', 'XRPUSDT.txt']\n",
      "Step 219, Best Reward: 0.28647664189338684\n",
      "Selected assets for this generation: ['ATOMUSDT.txt', 'XBTUSDT.txt', 'AVAXUSDT.txt', 'EOSUSDT.txt', 'MANAUSDT.txt', 'LINKUSDT.txt', 'LTCUSDT.txt', 'USDCUSDT.txt', 'SHIBUSDT.txt', 'SOLUSDT.txt']\n",
      "Step 218, Best Reward: 0.3193075656890869\n",
      "Selected assets for this generation: ['MANAUSDT.txt', 'ATOMUSDT.txt', 'DOTUSDT.txt', 'XTZUSDT.txt', 'XDGUSDT.txt', 'DAIUSDT.txt', 'XBTUSDT.txt', 'XMRUSDT.txt', 'EOSUSDT.txt', 'ADAUSDT.txt']\n",
      "Step 217, Best Reward: 0.3065984845161438\n",
      "Selected assets for this generation: ['XMRUSDT.txt', 'SOLUSDT.txt', 'XDGUSDT.txt', 'DOTUSDT.txt', 'USTUSDT.txt', 'APEUSDT.txt', 'ETHUSDT.txt', 'ATOMUSDT.txt', 'EOSUSDT.txt', 'LTCUSDT.txt']\n",
      "Step 216, Best Reward: 0.2934771180152893\n",
      "Selected assets for this generation: ['XTZUSDT.txt', 'ETHUSDT.txt', 'SHIBUSDT.txt', 'XMRUSDT.txt', 'AVAXUSDT.txt', 'APEUSDT.txt', 'DAIUSDT.txt', 'EOSUSDT.txt', 'XRPUSDT.txt', 'MANAUSDT.txt']\n",
      "Step 215, Best Reward: 0.3085966408252716\n",
      "Selected assets for this generation: ['ETHUSDT.txt', 'APEUSDT.txt', 'BCHUSDT.txt', 'USTUSDT.txt', 'SOLUSDT.txt', 'ATOMUSDT.txt', 'LTCUSDT.txt', 'XRPUSDT.txt', 'USDCUSDT.txt', 'ALGOUSDT.txt']\n",
      "Step 214, Best Reward: 0.27913206815719604\n",
      "Selected assets for this generation: ['XDGUSDT.txt', 'BCHUSDT.txt', 'ALGOUSDT.txt', 'MANAUSDT.txt', 'SOLUSDT.txt', 'APEUSDT.txt', 'EOSUSDT.txt', 'XTZUSDT.txt', 'ADAUSDT.txt', 'USTUSDT.txt']\n",
      "Step 213, Best Reward: 0.29787421226501465\n",
      "Selected assets for this generation: ['ATOMUSDT.txt', 'SHIBUSDT.txt', 'ADAUSDT.txt', 'LINKUSDT.txt', 'SOLUSDT.txt', 'ETHUSDT.txt', 'XDGUSDT.txt', 'DOTUSDT.txt', 'BCHUSDT.txt', 'AVAXUSDT.txt']\n",
      "Step 212, Best Reward: 0.298187792301178\n",
      "Selected assets for this generation: ['XBTUSDT.txt', 'AVAXUSDT.txt', 'ETHUSDT.txt', 'ALGOUSDT.txt', 'SHIBUSDT.txt', 'DOTUSDT.txt', 'APEUSDT.txt', 'EOSUSDT.txt', 'XTZUSDT.txt', 'ADAUSDT.txt']\n",
      "Step 211, Best Reward: 0.2914726138114929\n",
      "Selected assets for this generation: ['DOTUSDT.txt', 'XBTUSDT.txt', 'SOLUSDT.txt', 'ALGOUSDT.txt', 'SHIBUSDT.txt', 'APEUSDT.txt', 'BCHUSDT.txt', 'EOSUSDT.txt', 'XRPUSDT.txt', 'ATOMUSDT.txt']\n",
      "Step 210, Best Reward: 0.2948508858680725\n",
      "Selected assets for this generation: ['XRPUSDT.txt', 'SHIBUSDT.txt', 'XTZUSDT.txt', 'ADAUSDT.txt', 'ETHUSDT.txt', 'USTUSDT.txt', 'DOTUSDT.txt', 'ATOMUSDT.txt', 'XDGUSDT.txt', 'MANAUSDT.txt']\n",
      "Step 209, Best Reward: 0.2912074327468872\n",
      "Selected assets for this generation: ['SHIBUSDT.txt', 'ALGOUSDT.txt', 'USDCUSDT.txt', 'DAIUSDT.txt', 'SOLUSDT.txt', 'DOTUSDT.txt', 'USTUSDT.txt', 'ADAUSDT.txt', 'ETHUSDT.txt', 'MANAUSDT.txt']\n",
      "Step 208, Best Reward: 0.29503071308135986\n",
      "Selected assets for this generation: ['ALGOUSDT.txt', 'BCHUSDT.txt', 'XTZUSDT.txt', 'USTUSDT.txt', 'XRPUSDT.txt', 'ATOMUSDT.txt', 'XMRUSDT.txt', 'XBTUSDT.txt', 'USDCUSDT.txt', 'ETHUSDT.txt']\n",
      "Step 207, Best Reward: 0.2703409790992737\n",
      "Selected assets for this generation: ['APEUSDT.txt', 'EOSUSDT.txt', 'XMRUSDT.txt', 'ETHUSDT.txt', 'ADAUSDT.txt', 'USTUSDT.txt', 'DAIUSDT.txt', 'XDGUSDT.txt', 'DOTUSDT.txt', 'ALGOUSDT.txt']\n",
      "Step 206, Best Reward: 0.28720277547836304\n",
      "Selected assets for this generation: ['ATOMUSDT.txt', 'DAIUSDT.txt', 'SHIBUSDT.txt', 'XMRUSDT.txt', 'SOLUSDT.txt', 'MANAUSDT.txt', 'USTUSDT.txt', 'AVAXUSDT.txt', 'ETHUSDT.txt', 'BCHUSDT.txt']\n",
      "Step 205, Best Reward: 0.2647682726383209\n",
      "Selected assets for this generation: ['AVAXUSDT.txt', 'DAIUSDT.txt', 'XDGUSDT.txt', 'SHIBUSDT.txt', 'EOSUSDT.txt', 'USTUSDT.txt', 'LTCUSDT.txt', 'XTZUSDT.txt', 'APEUSDT.txt', 'XBTUSDT.txt']\n",
      "Step 204, Best Reward: 0.26148611307144165\n",
      "Selected assets for this generation: ['SHIBUSDT.txt', 'USTUSDT.txt', 'USDCUSDT.txt', 'DOTUSDT.txt', 'XDGUSDT.txt', 'DAIUSDT.txt', 'ATOMUSDT.txt', 'LINKUSDT.txt', 'BCHUSDT.txt', 'ALGOUSDT.txt']\n",
      "Step 203, Best Reward: 0.2920129895210266\n",
      "Selected assets for this generation: ['AVAXUSDT.txt', 'EOSUSDT.txt', 'XRPUSDT.txt', 'APEUSDT.txt', 'DOTUSDT.txt', 'BCHUSDT.txt', 'SOLUSDT.txt', 'ATOMUSDT.txt', 'ALGOUSDT.txt', 'ETHUSDT.txt']\n",
      "Step 202, Best Reward: 0.3098122179508209\n",
      "Selected assets for this generation: ['BCHUSDT.txt', 'DAIUSDT.txt', 'USTUSDT.txt', 'XDGUSDT.txt', 'XRPUSDT.txt', 'EOSUSDT.txt', 'MANAUSDT.txt', 'ETHUSDT.txt', 'ATOMUSDT.txt', 'USDCUSDT.txt']\n",
      "Step 201, Best Reward: 0.26819780468940735\n",
      "Selected assets for this generation: ['XTZUSDT.txt', 'EOSUSDT.txt', 'XRPUSDT.txt', 'USDCUSDT.txt', 'DAIUSDT.txt', 'XMRUSDT.txt', 'MANAUSDT.txt', 'LINKUSDT.txt', 'ALGOUSDT.txt', 'ETHUSDT.txt']\n",
      "Step 200, Best Reward: 0.2821790277957916\n",
      "Selected assets for this generation: ['LTCUSDT.txt', 'AVAXUSDT.txt', 'LINKUSDT.txt', 'SHIBUSDT.txt', 'DOTUSDT.txt', 'MANAUSDT.txt', 'XTZUSDT.txt', 'DAIUSDT.txt', 'APEUSDT.txt', 'XDGUSDT.txt']\n",
      "Step 199, Best Reward: 0.27767452597618103\n",
      "Selected assets for this generation: ['USTUSDT.txt', 'LINKUSDT.txt', 'ETHUSDT.txt', 'EOSUSDT.txt', 'MANAUSDT.txt', 'USDCUSDT.txt', 'XRPUSDT.txt', 'DOTUSDT.txt', 'XTZUSDT.txt', 'AVAXUSDT.txt']\n",
      "Step 198, Best Reward: 0.2796439230442047\n",
      "Selected assets for this generation: ['XMRUSDT.txt', 'ATOMUSDT.txt', 'USTUSDT.txt', 'XBTUSDT.txt', 'APEUSDT.txt', 'USDCUSDT.txt', 'ETHUSDT.txt', 'EOSUSDT.txt', 'ALGOUSDT.txt', 'LTCUSDT.txt']\n",
      "Step 197, Best Reward: 0.2741600275039673\n",
      "Selected assets for this generation: ['XMRUSDT.txt', 'SHIBUSDT.txt', 'MANAUSDT.txt', 'XDGUSDT.txt', 'BCHUSDT.txt', 'XRPUSDT.txt', 'ETHUSDT.txt', 'AVAXUSDT.txt', 'LTCUSDT.txt', 'DAIUSDT.txt']\n",
      "Step 196, Best Reward: 0.2881053686141968\n",
      "Selected assets for this generation: ['XTZUSDT.txt', 'BCHUSDT.txt', 'XRPUSDT.txt', 'SHIBUSDT.txt', 'XBTUSDT.txt', 'EOSUSDT.txt', 'ADAUSDT.txt', 'AVAXUSDT.txt', 'USDCUSDT.txt', 'LINKUSDT.txt']\n",
      "Step 195, Best Reward: 0.26759257912635803\n",
      "Selected assets for this generation: ['XTZUSDT.txt', 'XMRUSDT.txt', 'XBTUSDT.txt', 'DAIUSDT.txt', 'XDGUSDT.txt', 'BCHUSDT.txt', 'LINKUSDT.txt', 'SHIBUSDT.txt', 'XRPUSDT.txt', 'AVAXUSDT.txt']\n",
      "Step 194, Best Reward: 0.28719234466552734\n",
      "Selected assets for this generation: ['ALGOUSDT.txt', 'XTZUSDT.txt', 'ADAUSDT.txt', 'USTUSDT.txt', 'ATOMUSDT.txt', 'SOLUSDT.txt', 'APEUSDT.txt', 'LTCUSDT.txt', 'AVAXUSDT.txt', 'USDCUSDT.txt']\n",
      "Step 193, Best Reward: 0.2804087996482849\n",
      "Selected assets for this generation: ['SOLUSDT.txt', 'ALGOUSDT.txt', 'ATOMUSDT.txt', 'BCHUSDT.txt', 'LINKUSDT.txt', 'XTZUSDT.txt', 'DOTUSDT.txt', 'APEUSDT.txt', 'AVAXUSDT.txt', 'USDCUSDT.txt']\n",
      "Step 192, Best Reward: 0.3038814067840576\n",
      "Selected assets for this generation: ['ALGOUSDT.txt', 'EOSUSDT.txt', 'XBTUSDT.txt', 'ETHUSDT.txt', 'XTZUSDT.txt', 'APEUSDT.txt', 'XMRUSDT.txt', 'DAIUSDT.txt', 'MANAUSDT.txt', 'SOLUSDT.txt']\n",
      "Step 191, Best Reward: 0.2889880836009979\n",
      "Selected assets for this generation: ['XBTUSDT.txt', 'APEUSDT.txt', 'AVAXUSDT.txt', 'DOTUSDT.txt', 'USDCUSDT.txt', 'DAIUSDT.txt', 'ATOMUSDT.txt', 'ETHUSDT.txt', 'XRPUSDT.txt', 'ADAUSDT.txt']\n",
      "Step 190, Best Reward: 0.3110702633857727\n",
      "Selected assets for this generation: ['APEUSDT.txt', 'SHIBUSDT.txt', 'ADAUSDT.txt', 'XDGUSDT.txt', 'EOSUSDT.txt', 'LINKUSDT.txt', 'LTCUSDT.txt', 'AVAXUSDT.txt', 'ALGOUSDT.txt', 'DOTUSDT.txt']\n",
      "Step 189, Best Reward: 0.2828838527202606\n",
      "Selected assets for this generation: ['XBTUSDT.txt', 'MANAUSDT.txt', 'SOLUSDT.txt', 'XDGUSDT.txt', 'SHIBUSDT.txt', 'ALGOUSDT.txt', 'DOTUSDT.txt', 'APEUSDT.txt', 'LTCUSDT.txt', 'BCHUSDT.txt']\n",
      "Step 188, Best Reward: 0.27017825841903687\n",
      "Selected assets for this generation: ['ETHUSDT.txt', 'LINKUSDT.txt', 'USTUSDT.txt', 'XBTUSDT.txt', 'XMRUSDT.txt', 'DAIUSDT.txt', 'APEUSDT.txt', 'XTZUSDT.txt', 'USDCUSDT.txt', 'ALGOUSDT.txt']\n",
      "Step 187, Best Reward: 0.2696920931339264\n",
      "Selected assets for this generation: ['ATOMUSDT.txt', 'AVAXUSDT.txt', 'EOSUSDT.txt', 'LINKUSDT.txt', 'ALGOUSDT.txt', 'APEUSDT.txt', 'BCHUSDT.txt', 'DAIUSDT.txt', 'XRPUSDT.txt', 'SOLUSDT.txt']\n",
      "Step 186, Best Reward: 0.28494927287101746\n",
      "Selected assets for this generation: ['ATOMUSDT.txt', 'USTUSDT.txt', 'LINKUSDT.txt', 'XDGUSDT.txt', 'XBTUSDT.txt', 'XRPUSDT.txt', 'APEUSDT.txt', 'DOTUSDT.txt', 'SHIBUSDT.txt', 'DAIUSDT.txt']\n",
      "Step 185, Best Reward: 0.3003658056259155\n",
      "Selected assets for this generation: ['EOSUSDT.txt', 'ADAUSDT.txt', 'LINKUSDT.txt', 'ATOMUSDT.txt', 'ETHUSDT.txt', 'XRPUSDT.txt', 'DAIUSDT.txt', 'MANAUSDT.txt', 'XTZUSDT.txt', 'SOLUSDT.txt']\n",
      "Step 184, Best Reward: 0.2913903594017029\n",
      "Selected assets for this generation: ['MANAUSDT.txt', 'BCHUSDT.txt', 'EOSUSDT.txt', 'DAIUSDT.txt', 'ATOMUSDT.txt', 'SOLUSDT.txt', 'XMRUSDT.txt', 'APEUSDT.txt', 'SHIBUSDT.txt', 'AVAXUSDT.txt']\n",
      "Step 183, Best Reward: 0.2681279480457306\n",
      "Selected assets for this generation: ['XMRUSDT.txt', 'XTZUSDT.txt', 'USTUSDT.txt', 'ALGOUSDT.txt', 'ETHUSDT.txt', 'LTCUSDT.txt', 'XRPUSDT.txt', 'APEUSDT.txt', 'DAIUSDT.txt', 'LINKUSDT.txt']\n",
      "Step 182, Best Reward: 0.2886551022529602\n",
      "Selected assets for this generation: ['DOTUSDT.txt', 'ALGOUSDT.txt', 'SOLUSDT.txt', 'XMRUSDT.txt', 'BCHUSDT.txt', 'XBTUSDT.txt', 'ETHUSDT.txt', 'MANAUSDT.txt', 'USDCUSDT.txt', 'XRPUSDT.txt']\n",
      "Step 181, Best Reward: 0.27368950843811035\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def run(x_array, population, agent):\n",
    "    rewards = []\n",
    "    # Example of a random walk in the environment\n",
    "    for xp in population:\n",
    "        vector_to_parameters(torch.tensor(xp, dtype=torch.float32), agent.parameters())\n",
    "        rewards.append(batched_fitness_function(agent, x_array))\n",
    "    return rewards\n",
    "\n",
    "# Define hyperparameters\n",
    "POP_SIZE = 42\n",
    "SCALING = 0.1\n",
    "\n",
    "# Instantiate the model\n",
    "STATE_DIM = train_data[list(train_data.keys())[0]][0].shape[-1]  # Number of features\n",
    "ACTION_DIM = 2  # Buy, Sell\n",
    "EP_LEN = 55\n",
    "agent_model = CausalAttentionAgent(state_dim=STATE_DIM, num_heads=8, embed_dim=432, action_dim=ACTION_DIM, seq_len=seq_len)\n",
    "\n",
    "# Initialize population\n",
    "dim = parameters_to_vector(agent_model.parameters()).shape[0]\n",
    "population = torch.randn(POP_SIZE, dim) * SCALING\n",
    "\n",
    "def fitness_function(population, agent, train_data, num_assets=10, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Evaluate the fitness of the population on a randomly selected batch of assets.\n",
    "\n",
    "    Args:\n",
    "        population: The population of agent parameters.\n",
    "        agent: The trading agent model.\n",
    "        train_data: Dictionary of training data for all assets.\n",
    "        num_assets: Number of assets to randomly select for evaluation.\n",
    "        device: The device to run the computation on (\"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        Tensor of normalized rewards for each member of the population.\n",
    "    \"\"\"\n",
    "    # Move agent to the device\n",
    "    agent.to(device)\n",
    "\n",
    "    # Randomly select a batch of assets\n",
    "    selected_assets = random.sample(list(train_data.keys()), num_assets)\n",
    "    print(f\"Selected assets for this generation: {selected_assets}\")\n",
    "\n",
    "    # Combine states and price changes for the selected assets\n",
    "    batch_states = torch.stack([train_data[asset][0] for asset in selected_assets], dim=0).to(device)  # Shape: (batch, ep_len, seq_len, features)\n",
    "    batch_price_changes = torch.stack([train_data[asset][1] for asset in selected_assets], dim=0).to(device)  # Shape: (batch, ep_len)\n",
    "\n",
    "    # Initialize rewards for the population\n",
    "    population_rewards = torch.zeros(len(population), len(selected_assets), device=device)  # Shape: (population_size, num_assets)\n",
    "\n",
    "    for i, params in enumerate(population):\n",
    "        # Update the agent's parameters\n",
    "        vector_to_parameters(params.to(device), agent.parameters())\n",
    "\n",
    "        # Evaluate the agent on the batch\n",
    "        rewards = batched_fitness_function(agent, batch_states, batch_price_changes)  # Shape: (batch, 1)\n",
    "        population_rewards[i] = rewards.squeeze()  # Store rewards for this parameter set\n",
    "\n",
    "    # Normalize rewards per parameter set using softmax across assets\n",
    "    normalized_rewards = F.softmax(population_rewards, dim=0)  # Normalize across assets for each parameter set\n",
    "\n",
    "    # Sum normalized rewards across all assets for each parameter set\n",
    "    final_rewards = normalized_rewards.sum(dim=1)  # Shape: (population_size,)\n",
    "\n",
    "    return final_rewards\n",
    "\n",
    "# Train with diffusion evolution\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "scheduler = DDIMScheduler(num_step=233)\n",
    "population = population.to(device)  # Move population to GPU\n",
    "\n",
    "for t, alpha in scheduler:  # Number of training steps\n",
    "    rewards = fitness_function(population, agent_model, train_data, device=device)\n",
    "    print(f\"Step {t}, Best Reward: {max(rewards)}\")\n",
    "    population = population.cpu()  # Move population to CPU for generator\n",
    "    generator = BayesianGenerator(population, rewards.cpu(), alpha)\n",
    "    population = generator(noise=0).to(device)  # put new population on gpu\n",
    "\n",
    "    best_para = population[-1]\n",
    "    torch.save(best_para, 'best_attention_agent.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5147fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick5\\AppData\\Local\\Temp\\ipykernel_23640\\3515018346.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_params = torch.load(saved_population_path)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agent_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m saved_population_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_attention_agent.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m best_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(saved_population_path)\n\u001b[1;32m----> 5\u001b[0m current_params \u001b[38;5;241m=\u001b[39m parameters_to_vector(agent_model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(current_params\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_params\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Load the saved population\n",
    "saved_population_path = 'best_attention_agent.pth'\n",
    "best_params = torch.load(saved_population_path)\n",
    "agent_model = CausalAttentionAgent(state_dim=STATE_DIM, num_heads=8, embed_dim=432, action_dim=ACTION_DIM, seq_len=seq_len)\n",
    "current_params = parameters_to_vector(agent_model.parameters())\n",
    "print(current_params.shape)\n",
    "print(best_params.shape)\n",
    "vector_to_parameters(best_params, agent_model.parameters())\n",
    "# Evaluate the best parameters on the test set and plot performance\n",
    "def evaluate_population_on_test(agent, test_data, num_assets=10):\n",
    "    \"\"\"\n",
    "    Evaluate the saved population on the test set and plot performance.\n",
    "\n",
    "    Args:\n",
    "        agent: The trading agent model.\n",
    "        test_data: Dictionary of test data for all assets.\n",
    "        num_assets: Number of assets to randomly select for evaluation.\n",
    "\n",
    "    Returns:\n",
    "        List of rewards for the best parameters on the test set.\n",
    "    \"\"\"\n",
    "    # Randomly select a batch of assets\n",
    "    selected_assets = random.sample(list(test_data.keys()), num_assets)\n",
    "    print(f\"Selected assets for evaluation: {selected_assets}\")\n",
    "\n",
    "    # Combine states and price changes for the selected assets\n",
    "    batch_states = torch.stack([test_data[asset][0] for asset in selected_assets], dim=0)  # Shape: (batch, ep_len, seq_len, features)\n",
    "    batch_price_changes = torch.stack([test_data[asset][1] for asset in selected_assets], dim=0)  # Shape: (batch, ep_len)\n",
    "\n",
    "    # Load the best parameters into the agent\n",
    "    vector_to_parameters(best_params.cpu(), agent.parameters())\n",
    "\n",
    "    # Evaluate the agent on the test set\n",
    "    batch, ep_len = batch_price_changes.shape\n",
    "    print(batch_price_changes.shape)\n",
    "    rewards = torch.zeros(batch, ep_len)  # Initialize rewards for each asset over time\n",
    "\n",
    "    for t in range(ep_len - 1):\n",
    "        # Get the current state for all assets at time t\n",
    "        current_states = batch_states[:, t, :, :]  # Shape: (batch, seq_len, features)\n",
    "\n",
    "        # Get actions for all assets in the batch\n",
    "        actions = agent(current_states)  # Shape: (batch, 2) -> 2 actions: Buy, Sell\n",
    "        actions = torch.argmax(actions, dim=-1)  # Convert to discrete actions (0=Sell, 1=Buy)\n",
    "\n",
    "        # Convert actions to -1 (Sell) and 1 (Buy)\n",
    "        #actions = actions.float() * 2 - 1  # Map (0, 1) -> (-1, 1)\n",
    "        print(actions)\n",
    "        # Calculate rewards as the product of actions and percentage changes\n",
    "        rewards[:, t + 1] = rewards[:, t] + (actions * batch_price_changes[:, t + 1])\n",
    "\n",
    "    # Plot cumulative rewards for each asset\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, asset in enumerate(selected_assets):\n",
    "        plt.plot(rewards[i].numpy(), label=asset)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Cumulative Reward')\n",
    "    plt.title('Agent Performance on Selected Test Assets')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return rewards\n",
    "\n",
    "# Evaluate the best agent on the test set and plot performance\n",
    "test_rewards = evaluate_population_on_test(agent_model, test_data, num_assets=10)\n",
    "print(\"Test rewards for the best agent:\", test_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c8ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7eb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
